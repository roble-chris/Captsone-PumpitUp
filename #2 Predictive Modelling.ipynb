{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modelling : Multiclassification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Import libraries\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, average_precision_score\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, roc_curve, make_scorer\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, confusion_matrix,precision_recall_curve,confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, fbeta_score, roc_auc_score\n",
    "from sklearn.metrics import plot_precision_recall_curve, plot_confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Modeling\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict,GridSearchCV,RandomizedSearchCV, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_weighted']\n",
    "RSEED = 42\n",
    "pd.set_option('display.max_columns', 50)\n",
    "random_state = 100\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Dataset and Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of dataset after cleaning\n",
    "df = pd.read_csv('data/df_model.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Converting Labels  \n",
    "target_status_group = {'functional':2, 'functional needs repair': 1, 'non functional' : 0}\n",
    "df['status_group'] = df['status_group'].replace(target_status_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    32259\n",
       "0    22824\n",
       "1     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = df.drop([\"status_group\",'lga','recorded_by'], axis=1)\n",
    "y = df[\"status_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41580, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 23 columns):\n",
      "amount_tsh           59400 non-null float64\n",
      "gps_height           59400 non-null float64\n",
      "longitude            59400 non-null float64\n",
      "latitude             59400 non-null float64\n",
      "basin                59400 non-null object\n",
      "region               59400 non-null object\n",
      "lga                  59400 non-null object\n",
      "public_meeting       59400 non-null object\n",
      "recorded_by          59400 non-null object\n",
      "scheme_management    59400 non-null object\n",
      "permit               59400 non-null object\n",
      "construction_year    59400 non-null int64\n",
      "payment_type         59400 non-null object\n",
      "quality_group        59400 non-null object\n",
      "quantity             59400 non-null object\n",
      "source               59400 non-null object\n",
      "waterpoint_type      59400 non-null object\n",
      "status_group         59400 non-null int64\n",
      "funder_cat           59400 non-null object\n",
      "installer_cat        59400 non-null object\n",
      "extraction_custom    59400 non-null object\n",
      "management_custom    59400 non-null object\n",
      "population_log       59400 non-null float64\n",
      "dtypes: float64(5), int64(2), object(16)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basin',\n",
       " 'region',\n",
       " 'lga',\n",
       " 'public_meeting',\n",
       " 'recorded_by',\n",
       " 'scheme_management',\n",
       " 'permit',\n",
       " 'payment_type',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source',\n",
       " 'waterpoint_type',\n",
       " 'funder_cat',\n",
       " 'installer_cat',\n",
       " 'extraction_custom',\n",
       " 'management_custom']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\") \n",
    "cat_features = list(df.columns[df.dtypes==object])\n",
    "#cat_features.remove('status_group')\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_features.remove('permit')\n",
    "#cat_features.remove('public_meeting')\n",
    "cat_features.remove('lga')\n",
    "#cat_features.remove('ward')\n",
    "cat_features.remove('recorded_by')\n",
    "#cat_features.remove('region_code')\n",
    "#num_features.remove('num_private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basin',\n",
       " 'region',\n",
       " 'public_meeting',\n",
       " 'scheme_management',\n",
       " 'permit',\n",
       " 'payment_type',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source',\n",
       " 'waterpoint_type',\n",
       " 'funder_cat',\n",
       " 'installer_cat',\n",
       " 'extraction_custom',\n",
       " 'management_custom']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'construction_year',\n",
       " 'population_log']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "num_features = list(df.columns[df.dtypes!=object])\n",
    "num_features.remove('status_group')\n",
    "#num_features.remove('district_code')\n",
    "#num_features.remove('population')\n",
    "#num_features.remove('region_code')\n",
    "num_features\n",
    "#cat_features.remove('status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline using Pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (41580, 144)\n",
      "validation shape:  (17820, 144)\n"
     ]
    }
   ],
   "source": [
    "print('train shape: ', X_train_transformed.shape)\n",
    "print('validation shape: ',X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_encoder = preprocessor.named_transformers_[\"cat\"]['1hot']\n",
    "hot_encoder_names = hot_encoder.get_feature_names(cat_features)\n",
    "column_names = num_features + list(hot_encoder_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430976430976431"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DummyClassifier for multiclass target variable \n",
    "#(2 = 'functional', 1 = 'functional needs repair', 0 = 'non functional')\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "dummy.fit(X_train_transformed, y_train)\n",
    "dummy.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 54.31%\n",
      "Mean precision: 29.49%\n",
      "Mean recall: 54.31%\n"
     ]
    }
   ],
   "source": [
    "metrics = ['accuracy', 'precision_weighted', 'recall_weighted']\n",
    "scores_dummy = cross_validate(dummy, X_train_transformed, y_train, scoring=metrics, cv=5, n_jobs=-1)\n",
    "print('Mean accuracy: {:.2f}%'.format(scores_dummy['test_accuracy'].mean()*100))\n",
    "print('Mean precision: {:.2f}%'.format(scores_dummy['test_precision_weighted'].mean()*100))\n",
    "print('Mean recall: {:.2f}%'.format(scores_dummy['test_recall_weighted'].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select models for comparison\n",
    "models={'Baseline': DummyClassifier(strategy='most_frequent'),\n",
    "        'LogReg': LogisticRegression(max_iter=100),\n",
    "        #'KNN': KNeighborsClassifier(),\n",
    "        #'SVC': SVC(kernel='rbf', C=1E6),\n",
    "        'Decision Tree': DecisionTreeClassifier(criterion=\"gini\", max_depth=3,random_state=random_state),\n",
    "        'Random Forest': RandomForestClassifier(random_state=random_state, max_features='sqrt', n_jobs=-1),\n",
    "        #'Gradient Boost': GradientBoostingClassifier(random_state=random_state),\n",
    "        'XGBoost': XGBClassifier(),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=random_state)\n",
    "        \n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[    0     0 15977]\n",
      " [    0     0  3022]\n",
      " [    0     0 22581]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.9s finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[10235   124  5618]\n",
      " [  573   293  2156]\n",
      " [ 2241   121 20219]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.9s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Decision Tree: \n",
      "[[ 8638     0  7339]\n",
      " [  683     0  2339]\n",
      " [ 2228     0 20353]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.0s remaining:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.4s finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[12431   270  3276]\n",
      " [  467  1034  1521]\n",
      " [ 2214   676 19691]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.7min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.7min finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[ 9771    85  6121]\n",
      " [  382   304  2336]\n",
      " [ 1407    92 21082]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    8.3s remaining:   12.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[ 9907   139  5931]\n",
      " [  553   222  2247]\n",
      " [ 2370   170 20041]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.5s finished\n",
      "/Users/galopito/opt/anaconda3/envs/nf/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543074</td>\n",
       "      <td>0.382262</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.294929</td>\n",
       "      <td>0.543074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739466</td>\n",
       "      <td>0.717177</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.733222</td>\n",
       "      <td>0.739466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.697234</td>\n",
       "      <td>0.661340</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.655454</td>\n",
       "      <td>0.697234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.797403</td>\n",
       "      <td>0.791715</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.790723</td>\n",
       "      <td>0.797403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749327</td>\n",
       "      <td>0.724636</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.758308</td>\n",
       "      <td>0.749327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.725589</td>\n",
       "      <td>0.701868</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.712780</td>\n",
       "      <td>0.725589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 Score          Model  Precision    Recall\n",
       "0  0.543074  0.382262       Baseline   0.294929  0.543074\n",
       "1  0.739466  0.717177         LogReg   0.733222  0.739466\n",
       "2  0.697234  0.661340  Decision Tree   0.655454  0.697234\n",
       "3  0.797403  0.791715  Random Forest   0.790723  0.797403\n",
       "4  0.749327  0.724636        XGBoost   0.758308  0.749327\n",
       "5  0.725589  0.701868       AdaBoost   0.712780  0.725589"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scores = cross_validate(models, X_train, y_train, scoring=scoring, cv=3, n_jobs=-1, verbose=10)\n",
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "       \n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipeline,\n",
    "                                        X_train,\n",
    "                                        y_train.values.ravel(),\n",
    "                                        cv=5,\n",
    "                                        verbose=4,\n",
    "                                        n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "            \n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" + str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression (using pipeline)\n",
    "pipeline_logreg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cross_val_predict(pipeline_logreg,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.74\n",
      "Recall: 0.74\n",
      "Precision: 0.73\n",
      "F1 Score: 0.72\n",
      "Confusion Matrix: \n",
      "[[10262   119  5596]\n",
      " [  580   292  2150]\n",
      " [ 2251   121 20209]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression (using pipeline, printing results)\n",
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_pred,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_pred,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_train_pred,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_train_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunig with Gread Seach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters for grid-search (C initial: [0.01, 0.1, 1, 10, 100]; adapted according to optimal results)\n",
    "param_logreg = {'logreg__penalty':('l1','l2'),\n",
    "                'logreg__C': [0.05, 0.08, 0.1, 0.2, 0.5, 1],\n",
    "                'logreg__class_weight': [{0: x, 1: 1.0-x} for x in [0.25,0.5,0.75]]\n",
    "               }\n",
    "\n",
    "grid_logreg = GridSearchCV(pipeline_logreg, param_grid=param_logreg, cv=5, scoring=scoring, \n",
    "                           verbose=5, n_jobs=-1, refit='precision_weighted',return_train_score=True) # scoring can also be \"precision\", \"recall\", ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['amount_tsh',\n",
       "                                                                          'gps_height',\n",
       "                                                                          'longitude',\n",
       "                                                                          'latitude',\n",
       "                                                                          'construction_year',\n",
       "                                                                          'population_log']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('1hot',\n",
       "                                                                                          OneHotEncoder(sparse=False))]),\n",
       "                                                                         ['basin',\n",
       "                                                                          'region',\n",
       "                                                                          'public_meeting',\n",
       "                                                                          'scheme_managem...\n",
       "                                                                          'installer_cat',\n",
       "                                                                          'extraction_custom',\n",
       "                                                                          'management_custom'])])),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logreg__C': [0.05, 0.08, 0.1, 0.2, 0.5, 1],\n",
       "                         'logreg__class_weight': [{0: 0.25, 1: 0.75},\n",
       "                                                  {0: 0.5, 1: 0.5},\n",
       "                                                  {0: 0.75, 1: 0.25}],\n",
       "                         'logreg__penalty': ('l1', 'l2')},\n",
       "             refit='precision_weighted', return_train_score=True,\n",
       "             scoring=['precision_weighted'], verbose=5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "grid_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.76\n",
      "Best parameters:\n",
      "{'logreg__C': 0.5, 'logreg__class_weight': {0: 0.75, 1: 0.25}, 'logreg__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as best_model\n",
    "best_model_logreg = grid_logreg.best_estimator_['logreg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Recall: 0.73\n",
      "Precision: 0.75\n",
      "F1 Score: 0.70\n",
      "Confusion Matrix: \n",
      "[[4052    0 2795]\n",
      " [ 186    4 1105]\n",
      " [ 668    1 9009]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the optimized model\n",
    "y_pred_logreg = best_model_logreg.predict(X_test_transformed)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred_logreg)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_pred_logreg,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_pred_logreg,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_test, y_pred_logreg,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "pipeline_rf_clf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('rf_clf', RandomForestClassifier(n_estimators=100,\n",
    "                              random_state=random_state,\n",
    "                              max_depth=5,\n",
    "                              max_features=\"sqrt\",\n",
    "                              n_jobs=-1,\n",
    "                              class_weight='balanced',\n",
    "                              criterion= 'entropy',\n",
    "                              min_samples_split= 10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf_clf = cross_val_predict(pipeline_rf_clf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.64\n",
      "Recall: 0.64\n",
      "Precision: 0.73\n",
      "F1 Score: 0.67\n",
      "Confusion Matrix: \n",
      "[[ 9268  2382  4327]\n",
      " [  347  1730   945]\n",
      " [ 1961  4835 15785]]\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_pred_rf_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_pred_rf_clf,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_pred_rf_clf,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_train_pred_rf_clf,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_train_pred_rf_clf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameter space for grid-search\n",
    "param_grid = {'rf_clf__bootstrap': [True, False],\n",
    "              'rf_clf__max_depth': [2, 3, 5, 10, 20, 30,50,None],\n",
    "              'rf_clf__max_features': ['auto', 'sqrt',3,5,10,20],\n",
    "              'rf_clf__min_samples_leaf': [1, 2, 4],\n",
    "              'rf_clf__min_samples_split': [2, 5, 10],\n",
    "              'rf_clf__n_estimators': [10, 50, 100, 200, 400]} # Others: kernel, degree (only for poly)\n",
    "grid_rf_clf = RandomizedSearchCV(pipeline_rf_clf, param_grid, cv=5, scoring=scoring, \n",
    "                           verbose=10, n_jobs=-1, refit='precision_weighted',return_train_score=True, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  9.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('preprocessor',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('std_scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['amount_tsh',\n",
       "                                                                                'gps_height',\n",
       "                                                                                'longitude',\n",
       "                                                                                'latitude',\n",
       "                                                                                'construction_year',\n",
       "                                                                                'population_log']),\n",
       "                                                                              ('cat',\n",
       "                                                                               Pipeline(steps=[('1hot',\n",
       "                                                                                                OneHotEncoder(sparse=False))]),\n",
       "                                                                               ['basin',\n",
       "                                                                                'region',\n",
       "                                                                                'public_meeting',\n",
       "                                                                                'scheme_m...\n",
       "                   param_distributions={'rf_clf__bootstrap': [True, False],\n",
       "                                        'rf_clf__max_depth': [2, 3, 5, 10, 20,\n",
       "                                                              30, 50, None],\n",
       "                                        'rf_clf__max_features': ['auto', 'sqrt',\n",
       "                                                                 3, 5, 10, 20],\n",
       "                                        'rf_clf__min_samples_leaf': [1, 2, 4],\n",
       "                                        'rf_clf__min_samples_split': [2, 5, 10],\n",
       "                                        'rf_clf__n_estimators': [10, 50, 100,\n",
       "                                                                 200, 400]},\n",
       "                   refit='precision_weighted', return_train_score=True,\n",
       "                   scoring=['precision_weighted'], verbose=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "grid_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.80\n",
      "Best parameters:\n",
      "{'rf_clf__n_estimators': 400, 'rf_clf__min_samples_split': 5, 'rf_clf__min_samples_leaf': 1, 'rf_clf__max_features': 'sqrt', 'rf_clf__max_depth': None, 'rf_clf__bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as best_model\n",
    "best_model_rf_clf = grid_rf_clf.best_estimator_['rf_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Recall: 0.70\n",
      "Precision: 0.70\n",
      "F1 Score: 0.70\n",
      "Confusion Matrix: \n",
      "[[5375  212 1260]\n",
      " [ 193  599  503]\n",
      " [ 880  506 8292]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_clf = best_model_rf_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred_rf_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_pred_rf_clf,average='macro')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_pred_rf_clf,average='macro')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_test, y_pred_rf_clf,average='macro')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred_rf_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "pipe_xgb = Pipeline([('preprocess', preprocessor), \n",
    "                     ('xgb', XGBClassifier(random_state=RSEED))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_xgb_clf = cross_val_predict(pipe_xgb, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.77\n",
      "Recall: 0.77\n",
      "Precision: 0.78\n",
      "F1 Score: 0.76\n",
      "Confusion Matrix: \n",
      "[[10751    92  5134]\n",
      " [  438   497  2087]\n",
      " [ 1526   118 20937]]\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_pred_xgb_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_pred_xgb_clf,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_pred_xgb_clf,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_train_pred_xgb_clf,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_train_pred_xgb_clf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {\"xgb__learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30] ,\n",
    "             \"xgb__max_depth\": [5, 6, 8, 10, 12, 15, 17, 20],\n",
    "             \"xgb__min_child_weight\": [1, 3, 5],\n",
    "             \"xgb__gamma\": [0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "             \"xgb__colsample_bytree\" : [0.4, 0.5 , 0.7 ] \n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First RandomSearch for XGBoost\n",
    "grid_xgb = RandomizedSearchCV(pipe_xgb, \n",
    "                                param_distributions = param_xgb,\n",
    "                                n_iter = 50, cv = 3, scoring = scoring, \n",
    "                                verbose = 10, random_state=RSEED, n_jobs = -1,refit='precision_weighted',return_train_score=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 44.5min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 74.8min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 87.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 96.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 107.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 115.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocess',\n",
       "                                              ColumnTransformer(transformers=[('num',\n",
       "                                                                               Pipeline(steps=[('std_scaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['amount_tsh',\n",
       "                                                                                'gps_height',\n",
       "                                                                                'longitude',\n",
       "                                                                                'latitude',\n",
       "                                                                                'construction_year',\n",
       "                                                                                'population_log']),\n",
       "                                                                              ('cat',\n",
       "                                                                               Pipeline(steps=[('1hot',\n",
       "                                                                                                OneHotEncoder(sparse=False))]),\n",
       "                                                                               ['basin',\n",
       "                                                                                'region',\n",
       "                                                                                'public_meeting',\n",
       "                                                                                'scheme_man...\n",
       "                                              XGBClassifier(random_state=42))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'xgb__colsample_bytree': [0.4, 0.5,\n",
       "                                                                  0.7],\n",
       "                                        'xgb__gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'xgb__learning_rate': [0.05, 0.1, 0.15,\n",
       "                                                               0.2, 0.25, 0.3],\n",
       "                                        'xgb__max_depth': [5, 6, 8, 10, 12, 15,\n",
       "                                                           17, 20],\n",
       "                                        'xgb__min_child_weight': [1, 3, 5]},\n",
       "                   random_state=42, refit='precision_weighted',\n",
       "                   return_train_score=True, scoring=['precision_weighted'],\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.80\n",
      "Best parameters:\n",
      "{'xgb__min_child_weight': 1, 'xgb__max_depth': 12, 'xgb__learning_rate': 0.05, 'xgb__gamma': 0.3, 'xgb__colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as best_model\n",
    "best_model_xgb_clf = grid_xgb.best_estimator_['xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Recall: 0.81\n",
      "Precision: 0.81\n",
      "F1 Score: 0.79\n",
      "Confusion Matrix: \n",
      "[[5111   51 1685]\n",
      " [ 195  331  769]\n",
      " [ 670   91 8917]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb_clf = best_model_xgb_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred_xgb_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, y_pred_xgb_clf,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, y_pred_xgb_clf,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_test, y_pred_xgb_clf,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred_xgb_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "seed=100\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=seed)\n",
    "X_res, y_res = sm.fit_resample(X_train_transformed, y_train)\n",
    "X_res_tes, y_res_test = sm.fit_resample(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train_new, y_train_new = sm.fit_sample(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2d3170f0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_res_test).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a29bc5e80>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# observe that data has been balanced\n",
    "pd.Series(y_train_new).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_smote = Pipeline([('smote', SMOTE(sampling_strategy='minority')),\n",
    "                     ('xgb', XGBClassifier(random_state=RSEED))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Rufiji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-a65059f09c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_pred_xgb_clf_smote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    771\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    772\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 773\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    279\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pipeline'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 )\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_resample_one\u001b[0;34m(sampler, X, y, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    401\u001b[0m                       **fit_params):\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nf/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Rufiji'"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb_clf_smote = cross_val_predict(pipeline_smote, X_train_new, y_train_new, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.73\n",
      "Recall: 0.73\n",
      "Precision: 0.73\n",
      "F1 Score: 0.73\n",
      "Confusion Matrix: \n",
      "[[10024  1872  4081]\n",
      " [ 1508 17999  3074]\n",
      " [ 1926  4104 16551]]\n"
     ]
    }
   ],
   "source": [
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train_new, y_train_pred_xgb_clf_smote)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train_new, y_train_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train_new, y_train_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train_new, y_train_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train_new, y_train_pred_xgb_clf_smote)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Recall: 0.63\n",
      "Precision: 0.73\n",
      "F1 Score: 0.59\n",
      "Confusion Matrix: \n",
      "[[5111   51 1685]\n",
      " [1388 2374 5916]\n",
      " [ 670   91 8917]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb_clf_smote = best_model_xgb_clf.predict(X_res_tes)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_res_test, y_pred_xgb_clf_smote)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_res_test, y_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_res_test, y_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_res_test, y_pred_xgb_clf_smote,average='weighted')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_res_test, y_pred_xgb_clf_smote)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
